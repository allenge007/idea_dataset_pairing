filename,idea,dataset_name,dataset_description
-Closure_Structure_for_Studying_Data_Distribution.pdf,论文提出Δ-closure结构，用于研究二值数据集中闭合项集的分布和稳定性。通过引入Δ参数，扩展了传统的闭包操作符，使得能够量化闭合项集与其上邻之间的差异，并通过Δ等价类刻画数据的内在结构。实验表明，Δ较大的Δ等价类更加稳定，且该结构对数据采样不敏感，有助于发现对噪声和数据变化鲁棒的模式。,adult,"一个包含48,842个对象和95个属性的二值化数据集，源自美国人口普查数据，常用于分类和频繁模式挖掘任务。"
-Closure_Structure_for_Studying_Data_Distribution.pdf,论文提出Δ-closure结构，用于研究二值数据集中闭合项集的分布和稳定性。通过引入Δ参数，扩展了传统的闭包操作符，使得能够量化闭合项集与其上邻之间的差异，并通过Δ等价类刻画数据的内在结构。实验表明，Δ较大的Δ等价类更加稳定，且该结构对数据采样不敏感，有助于发现对噪声和数据变化鲁棒的模式。,chess (krk),"一个包含28,056个对象和40个属性的二值化数据集，源自国际象棋棋局数据，用于模式挖掘和数据分析。"
-Closure_Structure_for_Studying_Data_Distribution.pdf,论文提出Δ-closure结构，用于研究二值数据集中闭合项集的分布和稳定性。通过引入Δ参数，扩展了传统的闭包操作符，使得能够量化闭合项集与其上邻之间的差异，并通过Δ等价类刻画数据的内在结构。实验表明，Δ较大的Δ等价类更加稳定，且该结构对数据采样不敏感，有助于发现对噪声和数据变化鲁棒的模式。,cylinder bands,一个包含540个对象和120个属性的二值化工业数据集，用于研究工业过程中带状结构的频繁模式。
-Closure_Structure_for_Studying_Data_Distribution.pdf,论文提出Δ-closure结构，用于研究二值数据集中闭合项集的分布和稳定性。通过引入Δ参数，扩展了传统的闭包操作符，使得能够量化闭合项集与其上邻之间的差异，并通过Δ等价类刻画数据的内在结构。实验表明，Δ较大的Δ等价类更加稳定，且该结构对数据采样不敏感，有助于发现对噪声和数据变化鲁棒的模式。,horse colic,一个包含368个对象和81个属性的医疗数据集，用于分析马疝气疾病的诊断模式。
-Closure_Structure_for_Studying_Data_Distribution.pdf,论文提出Δ-closure结构，用于研究二值数据集中闭合项集的分布和稳定性。通过引入Δ参数，扩展了传统的闭包操作符，使得能够量化闭合项集与其上邻之间的差异，并通过Δ等价类刻画数据的内在结构。实验表明，Δ较大的Δ等价类更加稳定，且该结构对数据采样不敏感，有助于发现对噪声和数据变化鲁棒的模式。,ionosphere,一个包含351个对象和155个属性的雷达数据集，用于电离层反射信号的分类与模式分析。
-Closure_Structure_for_Studying_Data_Distribution.pdf,论文提出Δ-closure结构，用于研究二值数据集中闭合项集的分布和稳定性。通过引入Δ参数，扩展了传统的闭包操作符，使得能够量化闭合项集与其上邻之间的差异，并通过Δ等价类刻画数据的内在结构。实验表明，Δ较大的Δ等价类更加稳定，且该结构对数据采样不敏感，有助于发现对噪声和数据变化鲁棒的模式。,mushroom,"一个包含8,124个对象和88个属性的二值化数据集，用于研究蘑菇种类的频繁模式和分类。"
-Closure_Structure_for_Studying_Data_Distribution.pdf,论文提出Δ-closure结构，用于研究二值数据集中闭合项集的分布和稳定性。通过引入Δ参数，扩展了传统的闭包操作符，使得能够量化闭合项集与其上邻之间的差异，并通过Δ等价类刻画数据的内在结构。实验表明，Δ较大的Δ等价类更加稳定，且该结构对数据采样不敏感，有助于发现对噪声和数据变化鲁棒的模式。,nursery,"一个包含12,960个对象和27个属性的数据集，源自幼儿园入学评估数据，用于模式挖掘和数据分析。"
-Closure_Structure_for_Studying_Data_Distribution.pdf,论文提出Δ-closure结构，用于研究二值数据集中闭合项集的分布和稳定性。通过引入Δ参数，扩展了传统的闭包操作符，使得能够量化闭合项集与其上邻之间的差异，并通过Δ等价类刻画数据的内在结构。实验表明，Δ较大的Δ等价类更加稳定，且该结构对数据采样不敏感，有助于发现对噪声和数据变化鲁棒的模式。,pen digits,"一个包含10,992个对象和76个属性的手写数字数据集，用于模式识别和频繁项集挖掘。"
-Closure_Structure_for_Studying_Data_Distribution.pdf,论文提出Δ-closure结构，用于研究二值数据集中闭合项集的分布和稳定性。通过引入Δ参数，扩展了传统的闭包操作符，使得能够量化闭合项集与其上邻之间的差异，并通过Δ等价类刻画数据的内在结构。实验表明，Δ较大的Δ等价类更加稳定，且该结构对数据采样不敏感，有助于发现对噪声和数据变化鲁棒的模式。,soybean,一个包含683个对象和99个属性的农业数据集，用于分析大豆疾病诊断中的频繁模式。
1-s2.0-S0020025518302718-main.pdf,论文提出了一种结合话题图谱（topic map）与社交影响（social influence）的个性化混合推荐系统，旨在缓解冷启动问题并提升模型可扩展性。该方法利用用户生成的评论提取特征，并通过本体（BabelNet）将特征映射为话题以降低维度；同时，结合用户之间的社交关系（信任、友谊、相似兴趣）构建社会影响力网络，利用 closeness centrality 衡量用户影响力，从而提升推荐质量。,Yelp Dataset Challenge,"该数据集包含3276个用户、1493个商家（每个商家至少有2个用户的评论）以及从2005年至2015年间发布的14,003条评论。该数据集具有高度稀疏性，平均每个用户评论数量（NRU）约为4，其中约40%的用户仅发表过1条评论。该数据集被广泛用于推荐系统研究，特别是在处理冷启动问题和社交影响建模方面。"
1-s2.0-S0020025518306972-main.pdf,"本文提出了一种基于四元数提升方案（Quaternion Lifting Scheme, LQLS）的运动数据分类方法，用于步态识别。该方法利用四元数表示骨骼旋转数据，通过多分辨率分析提取旋转特征，并设计适用于四元数属性的最近邻和最小距离分类器进行识别。该方法避免了欧拉角表示的奇异性问题，提升了步态识别的精度，在包含30人的数据集上实现了超过96%的识别准确率。",PJAIT Human Motion Dataset,该数据集包含30名男性受试者的436次步态试验数据，年龄范围为20至40岁。数据由波兰-日本信息科技学院（PJAIT）的人体运动实验室采集，使用Vicon动作捕捉系统，包含骨骼运动数据。数据集中定义了两种步态类型：快速和慢速步态。每个样本的运动序列在时间域上被线性归一化为128个时间点，用于基于步态的人体识别任务。
1-s2.0-S0020025519301537-main.pdf,tcc2vec 是一种基于RFM信息增强的动态图表示学习方法，用于电信客户流失预测。该方法通过在增强的通话图中引入RFM行为特征，并结合时间窗口机制建模图的动态演化，从而自动学习客户节点的低维表示。相比传统手工特征工程和静态图表示方法，tcc2vec 能更有效地融合结构信息与行为信息，并提升流失预测的准确性和可解释性。,Call Detail Records (CDR),这是电信领域常用的标准化数据集类型，用于记录用户的通话行为，包括主叫、被叫、时间和通话时长等信息。论文中使用了预付费（prepaid）和后付费（postpaid）两种CDR数据集，每种数据集包含四个月的通话记录，且根据时间粒度划分为月级（monthly）、双周级（bi-weekly）和周级（weekly）等不同层次。这些数据集广泛用于客户流失预测、社交网络分析和用户行为建模。
1-s2.0-S0020025519304268-main.pdf,"论文提出了一种基于利润意识的集成选择（Profit-Conscious Ensemble Selection, PCES）框架，用于营销决策支持。该方法结合统计学习原则与商业目标，通过集成选择机制最大化营销活动的利润。PCES 在模型开发早期阶段引入商业目标，优化模型组合以提升实际业务价值，相比传统方法（如逻辑回归、随机森林和遗传算法优化）在多个真实数据集上显著提高了营销活动的盈利能力。",UCI Machine Learning Repository,UCI机器学习知识库是一个广泛使用的标准化数据集集合，包含大量用于机器学习研究的数据集。论文中使用了多个来自UCI的营销相关数据集，例如UCI-Adult和UCI-Coil，用于客户响应建模和盈利能力评分任务。这些数据集具有明确的特征定义和标签，适用于分类和预测建模任务。
1-s2.0-S0020025519304268-main.pdf,"论文提出了一种基于利润意识的集成选择（Profit-Conscious Ensemble Selection, PCES）框架，用于营销决策支持。该方法结合统计学习原则与商业目标，通过集成选择机制最大化营销活动的利润。PCES 在模型开发早期阶段引入商业目标，优化模型组合以提升实际业务价值，相比传统方法（如逻辑回归、随机森林和遗传算法优化）在多个真实数据集上显著提高了营销活动的盈利能力。",Data Mining Cup (DMC),Data Mining Cup 是一个面向数据挖掘竞赛的标准化数据集来源，被广泛用于营销和客户行为预测研究。论文中使用了多个 DMC 数据集（如 DMC01、DMC02、DMC04、DMC05、DMC06、DMC10），这些数据集通常涉及客户响应建模、盈利能力评分和客户流失预测任务，具有较高的行业相关性和现实营销场景代表性。
1-s2.0-S0020025519304268-main.pdf,"论文提出了一种基于利润意识的集成选择（Profit-Conscious Ensemble Selection, PCES）框架，用于营销决策支持。该方法结合统计学习原则与商业目标，通过集成选择机制最大化营销活动的利润。PCES 在模型开发早期阶段引入商业目标，优化模型组合以提升实际业务价值，相比传统方法（如逻辑回归、随机森林和遗传算法优化）在多个真实数据集上显著提高了营销活动的盈利能力。",ACM KDD Cup,ACM KDD Cup 是数据挖掘领域的重要竞赛平台，其发布的历史数据集（如 KDD98 和 KDD09）是学术界广泛认可的标准数据集。KDD98 被用于响应建模任务，而 KDD09 则用于客户流失预测。这些数据集包含大量客户特征和行为数据，适用于大规模预测建模。
1-s2.0-S0020025519304268-main.pdf,"论文提出了一种基于利润意识的集成选择（Profit-Conscious Ensemble Selection, PCES）框架，用于营销决策支持。该方法结合统计学习原则与商业目标，通过集成选择机制最大化营销活动的利润。PCES 在模型开发早期阶段引入商业目标，优化模型组合以提升实际业务价值，相比传统方法（如逻辑回归、随机森林和遗传算法优化）在多个真实数据集上显著提高了营销活动的盈利能力。",Consultancy Project (CP),虽然该数据集来源于咨询项目，但它是标准化的行业数据集，广泛用于营销建模研究。论文中使用了多个 CP 数据集（如 CP、CP-2017），这些数据集涵盖金融、电子商务、直销等多个行业，用于客户流失预测、响应建模等任务，具有较高的现实业务价值。
1-s2.0-S0020025519304451-main.pdf,论文提出了一种结合无监督与有监督学习的混合方法，用于信用卡欺诈检测。该方法通过在不同粒度级别（全局、本地、聚类）计算异常得分，并将这些异常得分作为特征增强原始特征空间，从而提升欺诈检测的准确性。创新点在于将“最佳结合”（best-of-both-worlds）原则应用于信用卡欺诈检测场景，并设计和评估了多种适应问题特性的异常得分。实验表明，在聚类粒度下结合GM-2等异常得分可显著提升AUC-PR等评估指标，证明了该方法在处理高不平衡欺诈检测问题上的有效性。,IEEE International Conference on Data Mining (ICDM) 2016,这是一个用于信用评分和欺诈检测研究的公开数据集，包含超过7600万笔真实信用卡交易记录。数据集涵盖了从2016年2月2日至2016年12月31日共计334天的交易数据。其中欺诈交易的比例为0.36%，属于高度类别不平衡的数据集。该数据集由工业合作伙伴Worldline提供，Worldline是一家全球领先的支付和交易服务公司。数据集的训练集为前8个月的数据（截至2016年9月30日），测试集为接下来的54天（2016年10月8日至12月31日）。
1-s2.0-S0020025520301808-main.pdf,该论文提出了一种基于边缘-云计算架构的隐私保护型自动情感识别系统。系统利用物联网设备采集用户的面部图像和语音信号，并通过秘密共享方案分发到不同的边缘云进行简单预处理，随后传输至核心云，采用预训练的卷积神经网络提取特征，再通过级联深度稀疏自编码器融合多模态特征，并最终由支持向量机进行情感分类。创新点包括：采用多秘密共享方案增强隐私保护、引入边缘计算降低传输负担、使用深度稀疏自编码器提升多模态特征融合效果。,RML数据库,RML数据库是一个公开可用的多模态情感识别数据集，包含音频和视频模态的用户情感数据，广泛用于评估情感识别系统的性能。
1-s2.0-S0020025520301808-main.pdf,该论文提出了一种基于边缘-云计算架构的隐私保护型自动情感识别系统。系统利用物联网设备采集用户的面部图像和语音信号，并通过秘密共享方案分发到不同的边缘云进行简单预处理，随后传输至核心云，采用预训练的卷积神经网络提取特征，再通过级联深度稀疏自编码器融合多模态特征，并最终由支持向量机进行情感分类。创新点包括：采用多秘密共享方案增强隐私保护、引入边缘计算降低传输负担、使用深度稀疏自编码器提升多模态特征融合效果。,eNTERFACE 05数据库,eNTERFACE 05数据库是一个包含面部图像和语音信号的多模态情感识别数据集，常用于训练和测试基于边缘与云计算的自动情感识别系统，具有较高的识别精度评估价值。
1-s2.0-S0020025520304758-main.pdf,本文提出了一种基于注意力机制的一致性语义学习方法（ACSL），用于微视频场景识别。该方法采用双分支框架结合注意力机制，通过提取时空特征并增强类内语义一致性，有效解决了微视频中因拍摄主观性导致的内容不一致问题。实验表明，ACSL 在多个数据集上优于传统动态场景识别方法，尤其在真实微视频场景中表现出更强的适应性和识别能力。,MicrovideoSceneData 10,这是一个专门为微视频场景识别任务构建的新数据集，通过对原始 Vine 平台公开数据重新组织而成。该数据集包含 10 个场景类别，每个类别的样本数量在 100 到 2000 之间，具有类别不平衡和内容不一致性的特点，更贴近真实微视频的分布特征。每个视频时长约 6 秒，摄像机处于运动状态，适用于评估微视频中场景识别方法的性能。
1-s2.0-S0020025520304758-main.pdf,本文提出了一种基于注意力机制的一致性语义学习方法（ACSL），用于微视频场景识别。该方法采用双分支框架结合注意力机制，通过提取时空特征并增强类内语义一致性，有效解决了微视频中因拍摄主观性导致的内容不一致问题。实验表明，ACSL 在多个数据集上优于传统动态场景识别方法，尤其在真实微视频场景中表现出更强的适应性和识别能力。,Maryland Dataset,这是一个常用于动态场景分类的标准数据集，包含 13 个动态场景类别，每个类别包含 10 个样本。视频来源于互联网（如 YouTube），具有光照变化大、图像尺度多样、摄像机运动等特点，广泛用于评估动态场景识别算法的泛化能力。
1-s2.0-S0020025520304758-main.pdf,本文提出了一种基于注意力机制的一致性语义学习方法（ACSL），用于微视频场景识别。该方法采用双分支框架结合注意力机制，通过提取时空特征并增强类内语义一致性，有效解决了微视频中因拍摄主观性导致的内容不一致问题。实验表明，ACSL 在多个数据集上优于传统动态场景识别方法，尤其在真实微视频场景中表现出更强的适应性和识别能力。,Yupenn Dataset,这是一个用于动态场景分类的公开数据集，包含 14 个场景类别，每个类别包含 30 个样本。视频由固定摄像机拍摄，时长约为 5 秒，适用于评估动态场景识别方法在固定视角下的性能。
1-s2.0-S0020025520305077-main.pdf,论文提出了一种基于离散余弦变换（DCT）的黑盒目标攻击方法，通过将图像从空间域转换到频率域，在保持对抗样本视觉不可察觉的前提下，有效减少查询次数，提高攻击效率。该方法能够在不依赖模型参数的情况下，针对YOLO v3和AWS Rekognition等黑盒目标检测系统实现对指定物体的精确欺骗，具有较高的攻击成功率和实用性。,COCO 2014,COCO（Common Objects in Context）2014是一个广泛使用的图像识别、目标检测和图像分割的标准数据集，包含超过8万张训练图像和4万张测试图像，涵盖80个常见物体类别。该数据集以复杂的日常场景为主，标注信息包括物体边界框、关键点和图像标题等，常用于评估计算机视觉模型在真实场景下的性能。
1-s2.0-S0020025520305363-main.pdf,"本文提出了一种基于“求偶学习”（Courtship Learning, CL）的改进火fly算法（FA），通过将种群分为雌性和雄性子种群，并引入雌性个体引导雄性个体移动的机制，增强算法的探索能力和种群多样性。具体来说，当雄性火fly被当前个体吸引但其亮度不足时，算法从雌性档案中选择一个优秀雌性个体来引导雄性个体移动，从而避免陷入局部最优。此外，提出了一种自适应吸引力参数v，使其随着个体间距离增加而增大，从而更好地平衡探索与开发。实验表明，CL框架显著提升了FA及其变体在CEC 2013基准函数上的优化性能。",CEC 2013 benchmark set,CEC 2013 benchmark set 是一个广泛用于评估全局优化算法性能的标准测试函数集，包含28个基准函数，分为5个单峰函数、15个基本多模态函数和8个复合函数。这些函数具有不同的复杂度和挑战性，适用于测试进化算法和群体智能算法的探索和开发能力。该数据集在优化领域被广泛采用，具有标准化和权威性。
1-s2.0-S0020025520305478-main.pdf,本文提出了一种基于梯度熵的梯度压缩机制EGC（Entropy-based Gradient Compression），通过计算每一层梯度的熵来动态确定梯度稀疏化阈值，从而在不牺牲模型准确率的前提下实现高梯度压缩比。该方法具有通用性和灵活性，适用于多种分布式训练场景（如去中心化训练、参数服务器架构和联邦学习），并通过引入学习率校正、动量校正和残差累积等机制进一步提升模型性能。实验表明，EGC在多个深度学习任务中可实现高达1000倍的梯度压缩比，同时保持甚至提升模型准确率。,MNIST,"MNIST是一个广泛使用的手写数字识别数据集，包含70,000张28×28灰度图像，分为10个类别（0-9的数字）。该数据集常用于图像分类和机器学习算法的基准测试。"
1-s2.0-S0020025520305478-main.pdf,本文提出了一种基于梯度熵的梯度压缩机制EGC（Entropy-based Gradient Compression），通过计算每一层梯度的熵来动态确定梯度稀疏化阈值，从而在不牺牲模型准确率的前提下实现高梯度压缩比。该方法具有通用性和灵活性，适用于多种分布式训练场景（如去中心化训练、参数服务器架构和联邦学习），并通过引入学习率校正、动量校正和残差累积等机制进一步提升模型性能。实验表明，EGC在多个深度学习任务中可实现高达1000倍的梯度压缩比，同时保持甚至提升模型准确率。,CIFAR-10,"CIFAR-10是一个用于图像分类任务的标准化数据集，包含60,000张32×32彩色图像，分为10个类别，如飞机、汽车、鸟等。该数据集广泛用于评估深度学习模型在小规模图像识别任务中的性能。"
1-s2.0-S0020025520305478-main.pdf,本文提出了一种基于梯度熵的梯度压缩机制EGC（Entropy-based Gradient Compression），通过计算每一层梯度的熵来动态确定梯度稀疏化阈值，从而在不牺牲模型准确率的前提下实现高梯度压缩比。该方法具有通用性和灵活性，适用于多种分布式训练场景（如去中心化训练、参数服务器架构和联邦学习），并通过引入学习率校正、动量校正和残差累积等机制进一步提升模型性能。实验表明，EGC在多个深度学习任务中可实现高达1000倍的梯度压缩比，同时保持甚至提升模型准确率。,Tiny ImageNet,Tiny ImageNet是ImageNet数据集的一个子集，包含200个类别，每个类别有500张训练图像、50张验证图像和50张测试图像。图像尺寸为64×64，常用于图像分类任务，尤其是在模型压缩和分布式训练研究中。
1-s2.0-S0020025520305478-main.pdf,本文提出了一种基于梯度熵的梯度压缩机制EGC（Entropy-based Gradient Compression），通过计算每一层梯度的熵来动态确定梯度稀疏化阈值，从而在不牺牲模型准确率的前提下实现高梯度压缩比。该方法具有通用性和灵活性，适用于多种分布式训练场景（如去中心化训练、参数服务器架构和联邦学习），并通过引入学习率校正、动量校正和残差累积等机制进一步提升模型性能。实验表明，EGC在多个深度学习任务中可实现高达1000倍的梯度压缩比，同时保持甚至提升模型准确率。,Penn Treebank (PTB),"Penn Treebank 是一个广泛使用的英语语料库，常用于语言建模任务。该数据集包含约923,000个训练词、73,000个验证词和82,000个测试词。通常用于评估循环神经网络（如LSTM）在语言建模中的性能。"
1-s2.0-S0020025520306058-main.pdf,本文提出了一种新的多标签分类方法MLWSE，通过加权堆叠集成和标签相关性建模，同时优化分类器权重和标签相关性。该方法利用稀疏正则化进行分类器选择，并结合标签相关性提高分类性能，适用于医学辅助诊断等实际应用场景。,Emotions,一个音乐领域的多标签分类数据集，包含593个实例，72个特征，6个标签，平均每个实例有1.868个标签
1-s2.0-S0020025520306058-main.pdf,本文提出了一种新的多标签分类方法MLWSE，通过加权堆叠集成和标签相关性建模，同时优化分类器权重和标签相关性。该方法利用稀疏正则化进行分类器选择，并结合标签相关性提高分类性能，适用于医学辅助诊断等实际应用场景。,Flags,一个图像领域的多标签分类数据集，包含194个实例，19个特征，7个标签，平均每个实例有3.392个标签
1-s2.0-S0020025520306058-main.pdf,本文提出了一种新的多标签分类方法MLWSE，通过加权堆叠集成和标签相关性建模，同时优化分类器权重和标签相关性。该方法利用稀疏正则化进行分类器选择，并结合标签相关性提高分类性能，适用于医学辅助诊断等实际应用场景。,Scene,一个图像领域的多标签分类数据集，包含2407个实例，294个特征，6个标签，平均每个实例有1.074个标签
1-s2.0-S0020025520306058-main.pdf,本文提出了一种新的多标签分类方法MLWSE，通过加权堆叠集成和标签相关性建模，同时优化分类器权重和标签相关性。该方法利用稀疏正则化进行分类器选择，并结合标签相关性提高分类性能，适用于医学辅助诊断等实际应用场景。,Yeast,一个生物领域的多标签分类数据集，包含2417个实例，103个特征，14个标签，平均每个实例有4.237个标签
1-s2.0-S0020025520306058-main.pdf,本文提出了一种新的多标签分类方法MLWSE，通过加权堆叠集成和标签相关性建模，同时优化分类器权重和标签相关性。该方法利用稀疏正则化进行分类器选择，并结合标签相关性提高分类性能，适用于医学辅助诊断等实际应用场景。,Birds,一个音频领域的多标签分类数据集，包含645个实例，260个特征，19个标签，平均每个实例有1.014个标签
1-s2.0-S0020025520306058-main.pdf,本文提出了一种新的多标签分类方法MLWSE，通过加权堆叠集成和标签相关性建模，同时优化分类器权重和标签相关性。该方法利用稀疏正则化进行分类器选择，并结合标签相关性提高分类性能，适用于医学辅助诊断等实际应用场景。,GpositiveGO,一个生物领域的多标签分类数据集，包含519个实例，912个特征，4个标签，平均每个实例有1.008个标签
1-s2.0-S0020025520306058-main.pdf,本文提出了一种新的多标签分类方法MLWSE，通过加权堆叠集成和标签相关性建模，同时优化分类器权重和标签相关性。该方法利用稀疏正则化进行分类器选择，并结合标签相关性提高分类性能，适用于医学辅助诊断等实际应用场景。,CHD-49,一个医学领域的多标签分类数据集，包含555个实例，49个特征，6个标签，平均每个实例有2.580个标签
1-s2.0-S0020025520306058-main.pdf,本文提出了一种新的多标签分类方法MLWSE，通过加权堆叠集成和标签相关性建模，同时优化分类器权重和标签相关性。该方法利用稀疏正则化进行分类器选择，并结合标签相关性提高分类性能，适用于医学辅助诊断等实际应用场景。,Enron,一个文本领域的多标签分类数据集，包含1702个实例，1001个特征，53个标签，平均每个实例有3.378个标签
1-s2.0-S0020025520306058-main.pdf,本文提出了一种新的多标签分类方法MLWSE，通过加权堆叠集成和标签相关性建模，同时优化分类器权重和标签相关性。该方法利用稀疏正则化进行分类器选择，并结合标签相关性提高分类性能，适用于医学辅助诊断等实际应用场景。,Langlog,一个文本领域的多标签分类数据集，包含1460个实例，1004个特征，75个标签，平均每个实例有1.180个标签
1-s2.0-S0020025520306058-main.pdf,本文提出了一种新的多标签分类方法MLWSE，通过加权堆叠集成和标签相关性建模，同时优化分类器权重和标签相关性。该方法利用稀疏正则化进行分类器选择，并结合标签相关性提高分类性能，适用于医学辅助诊断等实际应用场景。,Medical,一个文本领域的多标签分类数据集，包含978个实例，1449个特征，45个标签，平均每个实例有1.245个标签
1-s2.0-S0020025520306058-main.pdf,本文提出了一种新的多标签分类方法MLWSE，通过加权堆叠集成和标签相关性建模，同时优化分类器权重和标签相关性。该方法利用稀疏正则化进行分类器选择，并结合标签相关性提高分类性能，适用于医学辅助诊断等实际应用场景。,[SECURITY_TERM],一个生物领域的多标签分类数据集，包含207个实例，749个特征，6个标签，平均每个实例有1.217个标签
1-s2.0-S0020025520306058-main.pdf,本文提出了一种新的多标签分类方法MLWSE，通过加权堆叠集成和标签相关性建模，同时优化分类器权重和标签相关性。该方法利用稀疏正则化进行分类器选择，并结合标签相关性提高分类性能，适用于医学辅助诊断等实际应用场景。,Water-qy,一个化学领域的多标签分类数据集，包含1060个实例，16个特征，14个标签，平均每个实例有5.073个标签
1-s2.0-S0020025520306058-main.pdf,本文提出了一种新的多标签分类方法MLWSE，通过加权堆叠集成和标签相关性建模，同时优化分类器权重和标签相关性。该方法利用稀疏正则化进行分类器选择，并结合标签相关性提高分类性能，适用于医学辅助诊断等实际应用场景。,3s-bbc1000,一个文本领域的多标签分类数据集，包含352个实例，1000个特征，6个标签，平均每个实例有1.125个标签
1-s2.0-S0020025520306058-main.pdf,本文提出了一种新的多标签分类方法MLWSE，通过加权堆叠集成和标签相关性建模，同时优化分类器权重和标签相关性。该方法利用稀疏正则化进行分类器选择，并结合标签相关性提高分类性能，适用于医学辅助诊断等实际应用场景。,Cardiovascular and Cerebrovascular Disease (CCD),一个真实世界的医学多标签分类数据集，包含3823个实例，59个特征，9个标签，分别表示不同的疾病类别
1-s2.0-S0020025520306356-main.pdf,本文研究了基于反馈的序列动态事件推荐问题（SDERF），提出了两种在线学习模型——无上下文信息模型和有上下文信息模型。前者假设所有用户具有相似的内在兴趣，后者考虑不同用户的容忍度差异，并引入基于上置信界（UCB）的探索与利用算法，分别实现了对用户反馈的动态推荐策略优化。通过在真实数据集（Meetup 和 Damai）和合成数据集上的实验，验证了所提算法在降低平台用户流失率和累积遗憾方面的有效性。,Meetup,Meetup是一个事件社交平台的真实数据集，包含用户参与线下活动的记录。数据集包括多个城市（如温哥华、新加坡、奥克兰、北京）的用户信息、事件信息、用户标签、地理位置、用户参与或拒绝事件的反馈信息等。该数据集用于验证事件推荐算法在现实场景下的性能，尤其在用户兴趣、事件时间、距离等因素对推荐效果的影响。
1-s2.0-S0020025520306356-main.pdf,本文研究了基于反馈的序列动态事件推荐问题（SDERF），提出了两种在线学习模型——无上下文信息模型和有上下文信息模型。前者假设所有用户具有相似的内在兴趣，后者考虑不同用户的容忍度差异，并引入基于上置信界（UCB）的探索与利用算法，分别实现了对用户反馈的动态推荐策略优化。通过在真实数据集（Meetup 和 Damai）和合成数据集上的实验，验证了所提算法在降低平台用户流失率和累积遗憾方面的有效性。,Damai,大麦网（Damai）是中国的一个大型票务平台，提供演唱会、戏剧、体育赛事等文化娱乐活动的票务服务。该数据集包含50个热门事件和190个用户的真实反馈信息，每个事件包含用户的人口统计特征（如性别、年龄组、位置）和事件特征。该数据集用于评估事件推荐算法在实际商业场景中的表现。
1-s2.0-S0020025520306459-main.pdf,论文提出了一种高效的共现模式挖掘算法CMDS（Co-location Mining with Directed Road-Network Constraints and Spatial Continuity），用于在城市空间中挖掘受有向路网约束和空间连续性影响的最大共现模式。该算法设计了一个结合距离衰减效应和道路方向干扰的网络普遍性指标，并通过关键节点分离方法和改进的最短路径批量任务优化挖掘效率。实验表明，CMDS在处理城市空间共现问题时比现有方法更高效且准确。,Beijing POIs and road networks (2014),该数据集包含中国北京市怀柔区和石景山区的路网数据及兴趣点（POIs）数据。POIs数据由北京市工商行政管理局注册的合法实体组成，每个POIs具有唯一的地理坐标（XY坐标）和类别信息（如银行、餐厅等）。路网数据反映了城市道路的拓扑结构，包括道路方向和连接关系。该数据集用于验证在城市空间中受路网约束的共现模式挖掘算法，具有实际城市规划和资源分配的应用价值。
1-s2.0-S0020025520306460-main.pdf,"论文提出了一种基于差分进化算法（Differential Evolution, DE）的人脸识别框架FR-DE，通过优化预处理和特征提取技术组合，提高人脸识别系统在光照变化、姿态变化和单样本每人（OSPP）等挑战下的性能。该框架能够自动选择最优技术组合并调整参数，实验证明其在多个标准数据集上具有竞争力，特别是在光照补偿方面表现出色。",Yale Extended B,这是一个广泛用于人脸识别研究的公共数据集，因其包含多种光照条件而被高度使用。该数据集包含38个受试者在不同光照和姿态条件下的图像，每个受试者有9种姿态和64种光照条件的组合，图像尺寸为168x192。该数据集特别适用于研究光照变化对人脸识别系统的影响。
1-s2.0-S0020025520306460-main.pdf,"论文提出了一种基于差分进化算法（Differential Evolution, DE）的人脸识别框架FR-DE，通过优化预处理和特征提取技术组合，提高人脸识别系统在光照变化、姿态变化和单样本每人（OSPP）等挑战下的性能。该框架能够自动选择最优技术组合并调整参数，实验证明其在多个标准数据集上具有竞争力，特别是在光照补偿方面表现出色。",CMU-PIE,"CMU-PIE数据集包含68个受试者的41,368张图像，涵盖了13种姿态、43种光照条件和4种表情变化。该数据集常用于评估人脸识别算法在光照和姿态变化下的鲁棒性。研究中选取了五个子集（C05、C07、C09、C27、C29），每个子集代表不同的摄像机角度，用于分析单样本每人（OSPP）问题。"
1-s2.0-S0020025520306460-main.pdf,"论文提出了一种基于差分进化算法（Differential Evolution, DE）的人脸识别框架FR-DE，通过优化预处理和特征提取技术组合，提高人脸识别系统在光照变化、姿态变化和单样本每人（OSPP）等挑战下的性能。该框架能够自动选择最优技术组合并调整参数，实验证明其在多个标准数据集上具有竞争力，特别是在光照补偿方面表现出色。",FERET,FERET数据集是一个广泛使用的人脸识别基准数据集，包含1800张来自200个人的图像，图像尺寸为256x384，面部姿态角度从+60度到-60度不等。研究中使用了b系列子集，用于评估算法在姿态变化下的性能，特别是在单样本每人（OSPP）条件下的表现。
1-s2.0-S0020025520306484-main.pdf,本文提出了一种基于深度卷积生成对抗网络（DCGAN）的故障检测方法FaultFace，用于解决球轴承旋转轴连接件在不平衡数据条件下的故障识别问题。该方法通过将振动信号转换为二维“FacePortrait”图像表示，并利用DCGAN生成故障与正常状态的合成图像，构建平衡数据集，进而训练卷积神经网络（CNN）进行故障分类。该方法显著提升了在数据不平衡条件下的故障检测准确率，并通过结构相似性指数（SSIM）评估生成数据质量，验证了DCGAN在工业故障诊断中的有效性。,Case Western Reserve University (CWRU) Ball-Bearing Benchmark,这是一个广泛使用的工业故障检测标准数据集，用于评估旋转机械（特别是球轴承）的故障诊断方法。该数据集由美国凯斯西储大学（Case Western Reserve University）开发，包含114个振动信号数据集，其中4个为正常运行状态数据，其余为不同故障类型和故障直径的球轴承振动数据。数据采样频率分别为12 kHz（风扇端）和48 kHz（驱动端），涵盖了内圈故障、外圈故障（负载位置包括中心、对侧、正交）以及滚动体故障等多种故障类型。该数据集在工业设备故障诊断领域具有权威性，常用于验证不平衡数据下的故障分类算法。
1-s2.0-S0020025520306502-main.pdf,论文提出了一种基于深度学习的分布式集成堆叠自编码器（DE-SAE）模型，用于大规模多单元工业过程的非线性监控。该方法通过为每个操作单元建立局部自编码器模型提取局部特征，并利用互信息（MI）选择联合特征构建全局自编码器模型，从而实现局部和全局故障的同步监测。该方法不仅能有效识别局部故障和全局故障，还能提供更清晰的故障信息，辅助现场操作人员做出准确判断。,Tennessee-Eastman (TE) benchmark,Tennessee-Eastman过程是一个广泛用于过程监控研究的标准化仿真工业过程数据集。它模拟了一个实际的化工生产过程，包含多个操作单元和复杂的非线性关系。该数据集通常用于评估故障检测与诊断方法的有效性，包含多个正常和故障工况下的变量数据。论文中使用了其中的33个变量作为建模和测试变量，并设置了21种不同的故障类型进行实验验证。
1-s2.0-S0020025520306538-main.pdf,本文提出了一种基于变分自编码器（VAE）的非参数方法，用于评估两个高维样本集之间的距离，并进一步构建统计假设检验以判断它们是否来自相同分布。该方法通过训练两个 VAE 分别建模两个数据集的分布，使用对称的 Kullback-Leibler 散度衡量其生成分布之间的差异，并通过多次重拟合和排列检验构建统计显著性检验。该方法不仅提供了数值化的距离评估，还支持可视化分析，有助于理解高维数据之间的差异性和分离程度，在数据探索和分布漂移检测等任务中具有实用价值。,CIFAR-10,"CIFAR-10 是一个广泛使用的标准化图像数据集，包含 60,000 张 32x32 像素的彩色图像，分为 10 个类别（如飞机、汽车、鸟等），每个类别包含 6,000 张图像。该数据集常用于图像分类、生成模型和高维数据分析任务，是评估计算机视觉算法性能的基准数据集之一。"
1-s2.0-S0020025520306563-main.pdf,本文提出了一种基于多层邻域的贝叶斯个性化排序算法（BPRN），通过分析用户-物品相关性，将未评分物品分为邻域和非邻域集合，并结合贝叶斯个性化排序框架进行排序预测。该方法有效挖掘评分数据中的隐藏信息，提升了推荐系统的准确率，并缓解了数据稀疏性和冷启动问题。,MovieLens-100K (ML-100K),"一个广泛使用的电影评分数据集，包含943名用户对1682部电影的100,000条评分数据，评分范围为1至5分，评分矩阵密度为6.3%。该数据集常用于协同过滤和推荐系统的实验评估。"
1-s2.0-S0020025520306563-main.pdf,本文提出了一种基于多层邻域的贝叶斯个性化排序算法（BPRN），通过分析用户-物品相关性，将未评分物品分为邻域和非邻域集合，并结合贝叶斯个性化排序框架进行排序预测。该方法有效挖掘评分数据中的隐藏信息，提升了推荐系统的准确率，并缓解了数据稀疏性和冷启动问题。,MovieLens-1M (ML-1M),"一个更大规模的电影评分数据集，包含6040名用户对3706部电影的1,000,209条评分数据，评分范围也为1至5分，评分矩阵密度为4.5%。该数据集用于测试推荐系统在大规模数据下的性能。"
1-s2.0-S0020025520306563-main.pdf,本文提出了一种基于多层邻域的贝叶斯个性化排序算法（BPRN），通过分析用户-物品相关性，将未评分物品分为邻域和非邻域集合，并结合贝叶斯个性化排序框架进行排序预测。该方法有效挖掘评分数据中的隐藏信息，提升了推荐系统的准确率，并缓解了数据稀疏性和冷启动问题。,Ciao,"一个DVD产品评分数据集，包含7267名用户对11,211个DVD产品的149,147条评分数据，评分范围为1至5分，评分矩阵密度为1.8%。该数据集用于研究推荐系统在稀疏评分情况下的表现。"
1-s2.0-S0020025520306563-main.pdf,本文提出了一种基于多层邻域的贝叶斯个性化排序算法（BPRN），通过分析用户-物品相关性，将未评分物品分为邻域和非邻域集合，并结合贝叶斯个性化排序框架进行排序预测。该方法有效挖掘评分数据中的隐藏信息，提升了推荐系统的准确率，并缓解了数据稀疏性和冷启动问题。,Epinions,"一个在线产品评论数据集，包含7411名用户对8728个产品的276,116条评分数据，评分范围为1至5分，评分矩阵密度为4.3%。该数据集还包括用户之间的信任/不信任关系，适用于社交推荐系统研究。"
1-s2.0-S0020025520306563-main.pdf,本文提出了一种基于多层邻域的贝叶斯个性化排序算法（BPRN），通过分析用户-物品相关性，将未评分物品分为邻域和非邻域集合，并结合贝叶斯个性化排序框架进行排序预测。该方法有效挖掘评分数据中的隐藏信息，提升了推荐系统的准确率，并缓解了数据稀疏性和冷启动问题。,EachMovie,"一个电影推荐数据集，包含9095名用户对1566部电影的372,448条评分数据，评分范围为1分，步长为0.2。该数据集密度为2.6%，常用于早期协同过滤研究。"
1-s2.0-S0020025520306575-main.pdf,本文提出了一种用于多视角聚类的鲁棒亲和图表示学习框架。该框架包含两个关键阶段：1）从每个视角中构建鲁棒的超图拉普拉斯矩阵，采用结合超图嵌入与稀疏回归的改进特征选择方法提取显著特征；2）提出一致亲和图学习（CAGL）算法，通过融合所有视角的超图拉普拉斯矩阵，学习一个共享的潜在亲和矩阵，同时考虑聚类质量评估准则和基于Grassmann流形的一致性约束。该方法有效提升了多视角图像聚类的性能。,MIR Flickr 1M,这是一个广泛使用的网络图像数据集，包含约1百万张来自Flickr的图像，涵盖多个主题类别。论文中选取了其中10个标注完整的主题（如动物、云、花、室内、人物、建筑等），每个主题约200张图像。该数据集被用于多视角图像聚类实验，包含多种视觉特征（如HOG、LBP、HSV颜色相关图）和文本特征（TFID）。
1-s2.0-S0020025520306575-main.pdf,本文提出了一种用于多视角聚类的鲁棒亲和图表示学习框架。该框架包含两个关键阶段：1）从每个视角中构建鲁棒的超图拉普拉斯矩阵，采用结合超图嵌入与稀疏回归的改进特征选择方法提取显著特征；2）提出一致亲和图学习（CAGL）算法，通过融合所有视角的超图拉普拉斯矩阵，学习一个共享的潜在亲和矩阵，同时考虑聚类质量评估准则和基于Grassmann流形的一致性约束。该方法有效提升了多视角图像聚类的性能。,ETH-80,这是一个包含8个物体类别的图像数据集（如苹果、梨、番茄、牛、狗、马、杯子、汽车），每类包含10个物体实例，每个实例从41个不同视角拍摄。该数据集常用于多视角图像聚类和分类任务。
1-s2.0-S0020025520306575-main.pdf,本文提出了一种用于多视角聚类的鲁棒亲和图表示学习框架。该框架包含两个关键阶段：1）从每个视角中构建鲁棒的超图拉普拉斯矩阵，采用结合超图嵌入与稀疏回归的改进特征选择方法提取显著特征；2）提出一致亲和图学习（CAGL）算法，通过融合所有视角的超图拉普拉斯矩阵，学习一个共享的潜在亲和矩阵，同时考虑聚类质量评估准则和基于Grassmann流形的一致性约束。该方法有效提升了多视角图像聚类的性能。,COIL-20,哥伦比亚大学物体图像库（COIL-20）包含20个物体类别，每个类别有72张图像，分别从不同视角拍摄。该数据集用于评估多视角图像聚类方法，具有明显的视角变化。
1-s2.0-S0020025520306575-main.pdf,本文提出了一种用于多视角聚类的鲁棒亲和图表示学习框架。该框架包含两个关键阶段：1）从每个视角中构建鲁棒的超图拉普拉斯矩阵，采用结合超图嵌入与稀疏回归的改进特征选择方法提取显著特征；2）提出一致亲和图学习（CAGL）算法，通过融合所有视角的超图拉普拉斯矩阵，学习一个共享的潜在亲和矩阵，同时考虑聚类质量评估准则和基于Grassmann流形的一致性约束。该方法有效提升了多视角图像聚类的性能。,Honda/UCSD,该数据集包含20个不同人的59段人脸视频，每段视频包含12至645帧不等，包含大量头部姿态和面部表情变化。所有图像经过直方图均衡化处理以消除光照影响，常用于视频人脸聚类和识别任务。
1-s2.0-S0020025520306575-main.pdf,本文提出了一种用于多视角聚类的鲁棒亲和图表示学习框架。该框架包含两个关键阶段：1）从每个视角中构建鲁棒的超图拉普拉斯矩阵，采用结合超图嵌入与稀疏回归的改进特征选择方法提取显著特征；2）提出一致亲和图学习（CAGL）算法，通过融合所有视角的超图拉普拉斯矩阵，学习一个共享的潜在亲和矩阵，同时考虑聚类质量评估准则和基于Grassmann流形的一致性约束。该方法有效提升了多视角图像聚类的性能。,CMU Mobo,该数据集最初用于步态识别，包含24个不同人的96段视频，每人包含4种行走状态（慢走、快走、上坡走、抱球走），每段视频约300帧。论文中提取了LBP特征用于表示图像，适用于多视角图像聚类任务。
1-s2.0-S0020025520306587-main.pdf,本文提出了一种新的密度聚类方法——极端聚类（Extreme Clustering），通过识别密度极值点作为簇中心，解决了密度峰值聚类（Peak Clustering）在低密度簇中心识别困难和误将正常点识别为噪声的问题。该方法引入了基于簇大小的噪声检测机制，提升了算法在不同密度分布数据上的鲁棒性。实验表明，极端聚类在多个标准数据集上均优于Peak Clustering及其他主流聚类算法，并在实际雾霾源检测任务中展现了应用价值。,Olivetti,Olivetti数据集是一个人脸图像数据集，包含来自10个人的400张灰度图像（每人40张），图像尺寸为64×64像素。该数据集常用于人脸识别和聚类分析任务，具有一定的挑战性，因为图像在光照、角度和表情上存在变化。
1-s2.0-S0020025520306587-main.pdf,本文提出了一种新的密度聚类方法——极端聚类（Extreme Clustering），通过识别密度极值点作为簇中心，解决了密度峰值聚类（Peak Clustering）在低密度簇中心识别困难和误将正常点识别为噪声的问题。该方法引入了基于簇大小的噪声检测机制，提升了算法在不同密度分布数据上的鲁棒性。实验表明，极端聚类在多个标准数据集上均优于Peak Clustering及其他主流聚类算法，并在实际雾霾源检测任务中展现了应用价值。,Aggregation,Aggregation数据集是一个二维人工合成数据集，包含7个簇，共计788个数据点。该数据集的簇具有不规则形状和不同密度，广泛用于评估聚类算法在复杂结构上的表现。
1-s2.0-S0020025520306587-main.pdf,本文提出了一种新的密度聚类方法——极端聚类（Extreme Clustering），通过识别密度极值点作为簇中心，解决了密度峰值聚类（Peak Clustering）在低密度簇中心识别困难和误将正常点识别为噪声的问题。该方法引入了基于簇大小的噪声检测机制，提升了算法在不同密度分布数据上的鲁棒性。实验表明，极端聚类在多个标准数据集上均优于Peak Clustering及其他主流聚类算法，并在实际雾霾源检测任务中展现了应用价值。,S1,S1数据集是一个二维人工合成数据集，包含15个球形分布的簇，共计5000个数据点。该数据集用于评估聚类算法在高重叠度和高簇数情况下的性能。
1-s2.0-S0020025520306587-main.pdf,本文提出了一种新的密度聚类方法——极端聚类（Extreme Clustering），通过识别密度极值点作为簇中心，解决了密度峰值聚类（Peak Clustering）在低密度簇中心识别困难和误将正常点识别为噪声的问题。该方法引入了基于簇大小的噪声检测机制，提升了算法在不同密度分布数据上的鲁棒性。实验表明，极端聚类在多个标准数据集上均优于Peak Clustering及其他主流聚类算法，并在实际雾霾源检测任务中展现了应用价值。,Flame,Flame数据集是一个二维人工合成数据集，包含两个具有凹形结构的簇，共计240个数据点。该数据集用于测试聚类算法对非球形簇的识别能力。
1-s2.0-S0020025520306587-main.pdf,本文提出了一种新的密度聚类方法——极端聚类（Extreme Clustering），通过识别密度极值点作为簇中心，解决了密度峰值聚类（Peak Clustering）在低密度簇中心识别困难和误将正常点识别为噪声的问题。该方法引入了基于簇大小的噪声检测机制，提升了算法在不同密度分布数据上的鲁棒性。实验表明，极端聚类在多个标准数据集上均优于Peak Clustering及其他主流聚类算法，并在实际雾霾源检测任务中展现了应用价值。,Spiral,Spiral数据集是一个二维人工合成数据集，包含3个螺旋形状的簇，共计312个数据点。该数据集用于评估聚类算法在高度非线性结构上的表现。
1-s2.0-S0020025520306587-main.pdf,本文提出了一种新的密度聚类方法——极端聚类（Extreme Clustering），通过识别密度极值点作为簇中心，解决了密度峰值聚类（Peak Clustering）在低密度簇中心识别困难和误将正常点识别为噪声的问题。该方法引入了基于簇大小的噪声检测机制，提升了算法在不同密度分布数据上的鲁棒性。实验表明，极端聚类在多个标准数据集上均优于Peak Clustering及其他主流聚类算法，并在实际雾霾源检测任务中展现了应用价值。,Cancer,Cancer数据集（也称为乳腺癌威斯康星数据集）是一个真实世界分类数据集，包含569个样本，分为两类（恶性与良性），每个样本有30个特征。该数据集常用于医学分类和聚类任务。
1-s2.0-S0020025520306587-main.pdf,本文提出了一种新的密度聚类方法——极端聚类（Extreme Clustering），通过识别密度极值点作为簇中心，解决了密度峰值聚类（Peak Clustering）在低密度簇中心识别困难和误将正常点识别为噪声的问题。该方法引入了基于簇大小的噪声检测机制，提升了算法在不同密度分布数据上的鲁棒性。实验表明，极端聚类在多个标准数据集上均优于Peak Clustering及其他主流聚类算法，并在实际雾霾源检测任务中展现了应用价值。,A-sets,A-sets是一组人工合成的二维数据集（A1、A2、A3），每个数据集包含20个簇，簇的分布从均匀逐渐变为紧凑，用于评估聚类算法在不同簇紧密程度下的表现。
1-s2.0-S0020025520306587-main.pdf,本文提出了一种新的密度聚类方法——极端聚类（Extreme Clustering），通过识别密度极值点作为簇中心，解决了密度峰值聚类（Peak Clustering）在低密度簇中心识别困难和误将正常点识别为噪声的问题。该方法引入了基于簇大小的噪声检测机制，提升了算法在不同密度分布数据上的鲁棒性。实验表明，极端聚类在多个标准数据集上均优于Peak Clustering及其他主流聚类算法，并在实际雾霾源检测任务中展现了应用价值。,S-sets,S-sets是一组人工合成的二维数据集（S1、S2、S3、S4），每个数据集包含15个簇，簇之间的重叠程度逐渐增加，用于测试聚类算法在高重叠度下的鲁棒性。
1-s2.0-S0020025520305995-main.pdf,论文提出了一种基于多局部3D卷积神经网络与残差网络的区域预测模型LMST3D-ResNet，用于智慧城市中的区域电力使用和交通流量预测。该模型通过构建3D卷积和残差连接机制，有效提取局部区域的时空相关性，并融合趋势、周期和近期时间依赖关系以及外部因素，显著提升了预测精度。该方法在MLElectricity和BJTaxi两个真实数据集上验证了其优越性能。,MLElectricity,"该数据集包含米兰地区从2013年12月1日至2013年12月30日的571,392条电力使用记录。城市被划分为8×16个区域，每个时间间隔为10分钟。该数据集主要用于城市区域电力使用预测任务，仅包含流入数据，不包含流出数据。外部因素包括温度、天气状况和节假日信息。"
1-s2.0-S0020025520305995-main.pdf,论文提出了一种基于多局部3D卷积神经网络与残差网络的区域预测模型LMST3D-ResNet，用于智慧城市中的区域电力使用和交通流量预测。该模型通过构建3D卷积和残差连接机制，有效提取局部区域的时空相关性，并融合趋势、周期和近期时间依赖关系以及外部因素，显著提升了预测精度。该方法在MLElectricity和BJTaxi两个真实数据集上验证了其优越性能。,BJTaxi,该数据集由北京市的出租车流量数据组成，包含四个时间段：2013年7月1日至2013年10月30日、2014年3月1日至2014年6月30日、2015年3月1日至2015年6月30日、2015年11月1日至2016年4月10日。北京市被划分为32×32个区域，每个时间间隔为30分钟。该数据集用于预测区域内的车辆流入和流出情况，并考虑了外部模块因素，如天气和节假日。
1-s2.0-S0020025520306435-main.pdf,论文提出了一种基于回调感知的分层嵌入方法Callback2Vec，用于Android应用的代码表示学习。该方法通过区分普通API和回调函数，并在不同层级进行嵌入处理，能够有效捕捉事件驱动的回调上下文语义。其创新点包括：1）提出细粒度的回调序列生成算法，模拟应用运行时行为；2）构建分层嵌入模型，结合回调序列和回调内部代码令牌的语义信息；3）通过大规模公开数据集验证该方法在恶意模式识别、恶意分类和聚类等下游任务中的有效性，显著优于现有方法。,AMD (Android Malware Dataset),"这是一个广泛使用的标准化Android恶意软件数据集，包含了超过8,900个恶意APK文件，被学术界广泛用于Android恶意软件检测研究。该数据集按照恶意行为分类为42个类别和101个子类别，并提供了每个子类别的功能描述，用于支持恶意模式识别、分类和聚类等下游任务。"
1-s2.0-S0020025520306435-main.pdf,论文提出了一种基于回调感知的分层嵌入方法Callback2Vec，用于Android应用的代码表示学习。该方法通过区分普通API和回调函数，并在不同层级进行嵌入处理，能够有效捕捉事件驱动的回调上下文语义。其创新点包括：1）提出细粒度的回调序列生成算法，模拟应用运行时行为；2）构建分层嵌入模型，结合回调序列和回调内部代码令牌的语义信息；3）通过大规模公开数据集验证该方法在恶意模式识别、恶意分类和聚类等下游任务中的有效性，显著优于现有方法。,F-Droid,"F-Droid是一个知名的开源Android应用仓库，被用于提供大量良性的开源Android应用程序。论文中使用了来自F-Droid的3,100个APK作为良性样本，与AMD数据集结合进行恶意检测实验。该数据集被学术界广泛认可，常用于移动应用安全分析研究。"
1-s2.0-S0020025520306435-main.pdf,论文提出了一种基于回调感知的分层嵌入方法Callback2Vec，用于Android应用的代码表示学习。该方法通过区分普通API和回调函数，并在不同层级进行嵌入处理，能够有效捕捉事件驱动的回调上下文语义。其创新点包括：1）提出细粒度的回调序列生成算法，模拟应用运行时行为；2）构建分层嵌入模型，结合回调序列和回调内部代码令牌的语义信息；3）通过大规模公开数据集验证该方法在恶意模式识别、恶意分类和聚类等下游任务中的有效性，显著优于现有方法。,Fossdroid,"Fossdroid是另一个提供开源Android应用程序的平台，与F-Droid类似，也被用于提供良性样本。在论文中，它与F-Droid一起构成了实验中的良性应用数据集，总计3,100个应用。"
1-s2.0-S0020025520306332-main.pdf,本文提出了一种高效的分层代理辅助差分进化算法（EHSDE），用于解决高维昂贵优化问题。EHSDE采用分层代理框架，首先通过全局代理模型筛选出最优个体，同时根据欧氏距离筛选出最不确定个体以增强探索能力；随后在局部搜索阶段构建两个局部代理模型，分别基于最有前景的样本点和当前最优解周围的样本点，以加速收敛。该方法在CEC 2005基准函数和实际油藏优化问题上均表现出优于现有先进算法的性能，尤其在高维情况下具有良好的收敛性和稳定性。,CEC 2005 benchmark functions,CEC 2005基准函数集是一个广泛用于评估优化算法性能的标准测试集，包含多个具有不同特性的高维数值优化问题。该基准集包括单峰函数（如Ellipsoid）、多峰函数（如Rosenbrock、Ackley、Griewank）以及高度复杂的混合函数（如Shifted Rotated Rastrigin、Rotated Hybrid Composition Functions）。函数维度覆盖20D、30D、50D和100D，适合测试算法在高维昂贵优化问题上的收敛性和稳定性。
1-s2.0-S0020025520306642-main.pdf,DeepEmLAN 提出了一种基于深度注意力模型的属性网络嵌入方法，能够同时保留网络的拓扑结构、多类型属性（如文本和标签）以及节点间的语义关系。通过设计多目标损失函数和启发式组合策略，将不同信息源融合到统一的语义空间中，提升了节点分类和网络重建任务的性能。,Cora,Cora 是一个学术论文引用网络数据集，包含 2708 篇机器学习领域的论文，共 5429 条引用关系。每篇论文由一个 1433 维的二值词向量表示，表示论文中是否包含特定关键词。该数据集广泛用于节点分类、链接预测和图嵌入任务。
1-s2.0-S0020025520306642-main.pdf,DeepEmLAN 提出了一种基于深度注意力模型的属性网络嵌入方法，能够同时保留网络的拓扑结构、多类型属性（如文本和标签）以及节点间的语义关系。通过设计多目标损失函数和启发式组合策略，将不同信息源融合到统一的语义空间中，提升了节点分类和网络重建任务的性能。,Citeseer,Citeseer 是一个学术文献引用网络数据集，包含 3312 篇计算机科学和信息科学领域的论文，共 4732 条引用链接。每篇论文由一个 3703 维的二值词向量表示，表示从论文标题和摘要中提取的关键词存在情况。该数据集常用于图嵌入、节点分类和网络表示学习任务。
1-s2.0-S0020025520306642-main.pdf,DeepEmLAN 提出了一种基于深度注意力模型的属性网络嵌入方法，能够同时保留网络的拓扑结构、多类型属性（如文本和标签）以及节点间的语义关系。通过设计多目标损失函数和启发式组合策略，将不同信息源融合到统一的语义空间中，提升了节点分类和网络重建任务的性能。,Wiki,Wiki 是一个从维基百科爬取的知识图谱数据集，包含 2405 篇百科条目，共 17981 条页面间链接。每篇文章由一个 4973 维的二值词向量表示，表示文本中关键词的存在情况。该数据集用于图嵌入、节点分类和网络重建任务。
1-s2.0-S0020025520306708-main.pdf,论文提出了一种基于YOLOv3目标检测和混沌图像加密的新型图像加密方法Cy，用于在社交媒体平台上实现用户指定区域（ROI）的图像数据保护。该方法结合了深度学习的自动区域检测能力和混沌系统的加密优势，支持对图像中特定区域进行高效加密与解密，提升了加密选择性和实时性，适用于在线社交平台中的隐私保护场景。,COCO,COCO（Common Objects in Context）是一个广泛使用的计算机视觉数据集，包含超过33万张图像，涵盖80个对象类别，常用于目标检测、语义分割和图像生成任务。该数据集提供了详细的对象边界框和像素级标注信息，适用于评估图像处理算法的性能。
1-s2.0-S0020025520306708-main.pdf,论文提出了一种基于YOLOv3目标检测和混沌图像加密的新型图像加密方法Cy，用于在社交媒体平台上实现用户指定区域（ROI）的图像数据保护。该方法结合了深度学习的自动区域检测能力和混沌系统的加密优势，支持对图像中特定区域进行高效加密与解密，提升了加密选择性和实时性，适用于在线社交平台中的隐私保护场景。,flickr8k,"flickr8k 是一个常用的图像描述生成任务数据集，包含8,000张从Flickr网站收集的图像，每张图像配有多个由人工标注的描述语句。该数据集广泛用于图像理解、图像描述生成和多模态学习任务。"
1-s2.0-S0020025520306733-main.pdf,论文提出了一种基于动态链接表和自适应学习机制的改进型 Growing Neural Gas 算法（GNG-L），用于实时监测和追踪非平稳环境下的数据流漂移与奇异点。该方法通过自适应学习系数、神经节点删除机制和生成机制，实现了对数据流拓扑结构的高效建模与动态更新，具有良好的适应性和拓扑保持能力，适用于实时非平稳数据流的聚类与监控。,ImageNet,ImageNet 是一个大规模图像识别数据集，包含超过1400万张图像，涵盖超过2万多个类别。该数据集广泛用于图像分类、目标检测和深度学习模型的基准测试。
1-s2.0-S0020025520306733-main.pdf,论文提出了一种基于动态链接表和自适应学习机制的改进型 Growing Neural Gas 算法（GNG-L），用于实时监测和追踪非平稳环境下的数据流漂移与奇异点。该方法通过自适应学习系数、神经节点删除机制和生成机制，实现了对数据流拓扑结构的高效建模与动态更新，具有良好的适应性和拓扑保持能力，适用于实时非平稳数据流的聚类与监控。,COCO,COCO（Common Objects in Context）是一个用于目标检测、语义分割和图像字幕生成的大规模数据集，包含超过33万张图像，标注了80个常见物体类别，并提供了边界框和像素级标注。
1-s2.0-S0020025520306733-main.pdf,论文提出了一种基于动态链接表和自适应学习机制的改进型 Growing Neural Gas 算法（GNG-L），用于实时监测和追踪非平稳环境下的数据流漂移与奇异点。该方法通过自适应学习系数、神经节点删除机制和生成机制，实现了对数据流拓扑结构的高效建模与动态更新，具有良好的适应性和拓扑保持能力，适用于实时非平稳数据流的聚类与监控。,MNIST,MNIST 是一个手写数字图像数据集，包含7万张28x28灰度图像，广泛用于图像分类和机器学习算法的基准测试。
1-s2.0-S0020025520306733-main.pdf,论文提出了一种基于动态链接表和自适应学习机制的改进型 Growing Neural Gas 算法（GNG-L），用于实时监测和追踪非平稳环境下的数据流漂移与奇异点。该方法通过自适应学习系数、神经节点删除机制和生成机制，实现了对数据流拓扑结构的高效建模与动态更新，具有良好的适应性和拓扑保持能力，适用于实时非平稳数据流的聚类与监控。,CIFAR-10,CIFAR-10 是一个包含6万张32x32彩色图像的小规模图像数据集，图像分为10个类别，常用于图像分类和卷积神经网络的训练与测试。
1-s2.0-S0020025520306770-main.pdf,本文提出了一种层次化负采样方法（HNS），通过建模节点的潜在社区结构来改进网络表示学习中的负样本选择。HNS 不依赖于节点频率或手动设定邻居等级，而是利用分层狄利克雷过程（HDP）自动发现节点之间的潜在社区结构，并基于反转的社区-节点分布选择更合适的负样本，从而提升节点分类任务的性能。该方法在多个真实世界网络数据集上表现出优于现有负采样方法的效果，具有良好的鲁棒性和自动适应能力。,Cora,Cora 是一个典型的引文网络数据集，包含 2211 篇机器学习领域的论文，分为 7 个类别，包含 5214 条引文关系。该数据集广泛用于图表示学习、节点分类和链接预测任务，是网络表示学习领域最常用的标准数据集之一。
1-s2.0-S0020025520306770-main.pdf,本文提出了一种层次化负采样方法（HNS），通过建模节点的潜在社区结构来改进网络表示学习中的负样本选择。HNS 不依赖于节点频率或手动设定邻居等级，而是利用分层狄利克雷过程（HDP）自动发现节点之间的潜在社区结构，并基于反转的社区-节点分布选择更合适的负样本，从而提升节点分类任务的性能。该方法在多个真实世界网络数据集上表现出优于现有负采样方法的效果，具有良好的鲁棒性和自动适应能力。,DBLP,DBLP 是一个计算机科学领域的文献数据集，由多个研究领域的会议论文组成。在本文中，DBLP 数据集包含 17725 篇论文和 52914 条引文链接，涵盖数据库、数据挖掘、人工智能和计算机视觉四个领域，常用于评估节点分类和社区检测算法。
1-s2.0-S0020025520306770-main.pdf,本文提出了一种层次化负采样方法（HNS），通过建模节点的潜在社区结构来改进网络表示学习中的负样本选择。HNS 不依赖于节点频率或手动设定邻居等级，而是利用分层狄利克雷过程（HDP）自动发现节点之间的潜在社区结构，并基于反转的社区-节点分布选择更合适的负样本，从而提升节点分类任务的性能。该方法在多个真实世界网络数据集上表现出优于现有负采样方法的效果，具有良好的鲁棒性和自动适应能力。,Wiki,Wiki 是一个语言网络数据集，包含 2405 个维基网页，分为 17 个类别，拥有 17981 条链接。该数据集最初由 LBC 项目发布，广泛用于节点分类任务，是评估网络表示学习方法的重要基准数据集。
1-s2.0-S0020025520306782-main.pdf,本文提出了一种基于自指导学习的云资源管理工作负载预测模型（SDWF），通过计算最近预测的误差趋势来改进未来预测的准确性。该模型改进了基于黑洞现象的启发式优化算法，用于神经网络权重的训练，提升了预测精度。实验表明，该方法在多个真实世界数据集上的均方预测误差相比现有方法最高降低了99.99%。,NASA Kennedy Space Center HTTP Web Logs,该数据集包含来自NASA肯尼迪航天中心WWW服务器的HTTP请求日志，记录了两个月的请求数据，每个记录包含主机名、时间戳、请求内容、HTTP回复代码和字节数等信息。由于计算资源限制，实验中仅使用了一个月的数据。
1-s2.0-S0020025520306782-main.pdf,本文提出了一种基于自指导学习的云资源管理工作负载预测模型（SDWF），通过计算最近预测的误差趋势来改进未来预测的准确性。该模型改进了基于黑洞现象的启发式优化算法，用于神经网络权重的训练，提升了预测精度。实验表明，该方法在多个真实世界数据集上的均方预测误差相比现有方法最高降低了99.99%。,University of Calgary HTTP Web Logs,该数据集由加拿大卡尔加里大学计算机科学系WWW服务器一年的HTTP请求日志组成，记录了详细的Web访问行为，用于评估服务器负载预测模型在长时间跨度下的性能。
1-s2.0-S0020025520306782-main.pdf,本文提出了一种基于自指导学习的云资源管理工作负载预测模型（SDWF），通过计算最近预测的误差趋势来改进未来预测的准确性。该模型改进了基于黑洞现象的启发式优化算法，用于神经网络权重的训练，提升了预测精度。实验表明，该方法在多个真实世界数据集上的均方预测误差相比现有方法最高降低了99.99%。,University of Saskatchewan HTTP Web Logs,该数据集包含加拿大萨斯喀彻温大学WWW服务器七个月的HTTP请求日志，与卡尔加里数据集类似，用于分析Web服务器请求模式并验证预测模型的有效性。
1-s2.0-S0020025520306782-main.pdf,本文提出了一种基于自指导学习的云资源管理工作负载预测模型（SDWF），通过计算最近预测的误差趋势来改进未来预测的准确性。该模型改进了基于黑洞现象的启发式优化算法，用于神经网络权重的训练，提升了预测精度。实验表明，该方法在多个真实世界数据集上的均方预测误差相比现有方法最高降低了99.99%。,Google Cluster Traces (CPU),"该数据集由Google于2011年发布，包含来自其集群单元29天的CPU资源请求数据，涵盖了超过10,000台机器、670,000个任务和2000万个任务，是评估云资源管理算法的重要基准数据集。"
1-s2.0-S0020025520306782-main.pdf,本文提出了一种基于自指导学习的云资源管理工作负载预测模型（SDWF），通过计算最近预测的误差趋势来改进未来预测的准确性。该模型改进了基于黑洞现象的启发式优化算法，用于神经网络权重的训练，提升了预测精度。实验表明，该方法在多个真实世界数据集上的均方预测误差相比现有方法最高降低了99.99%。,Google Cluster Traces (Memory),该数据集与Google CPU请求数据集配套，记录了Google集群中内存资源的使用情况，用于评估内存需求预测模型的性能。
1-s2.0-S0020025520306782-main.pdf,本文提出了一种基于自指导学习的云资源管理工作负载预测模型（SDWF），通过计算最近预测的误差趋势来改进未来预测的准确性。该模型改进了基于黑洞现象的启发式优化算法，用于神经网络权重的训练，提升了预测精度。实验表明，该方法在多个真实世界数据集上的均方预测误差相比现有方法最高降低了99.99%。,PlanetLab CPU Utilization Trace,该数据集记录了PlanetLab平台上超过1000个虚拟机的CPU利用率，采样间隔为5分钟，覆盖全球500多个地点。实验中随机选取了22个虚拟机的数据用于评估模型在不同地理位置下的预测能力。
1-s2.0-S0020025520306794-main.pdf,论文提出了一种改进的SMOTE方法——RCSMOTE（Range-Controlled SMOTE），旨在同时解决SMOTE算法在不平衡数据处理中存在的三个主要问题：1）噪声样本的过采样导致泛化问题；2）无信息样本的过采样；3）类别边界区域重叠增加。该方法通过引入样本分类机制，识别适合过采样的样本，并在特征空间中计算一个“安全范围”来控制新样本的生成位置，防止其落入多数类区域，从而提升分类性能。,KEEL-dataset,KEEL（Knowledge Extraction based on Evolutionary Learning）数据集仓库提供了一系列标准化的不平衡数据集，广泛用于机器学习和数据挖掘研究。这些数据集涵盖了多种分类问题，具有不同的类别分布、特征维度和样本数量，适用于评估不平衡数据处理方法的性能。
1-s2.0-S0020025520306794-main.pdf,论文提出了一种改进的SMOTE方法——RCSMOTE（Range-Controlled SMOTE），旨在同时解决SMOTE算法在不平衡数据处理中存在的三个主要问题：1）噪声样本的过采样导致泛化问题；2）无信息样本的过采样；3）类别边界区域重叠增加。该方法通过引入样本分类机制，识别适合过采样的样本，并在特征空间中计算一个“安全范围”来控制新样本的生成位置，防止其落入多数类区域，从而提升分类性能。,UCI Machine Learning Repository,UCI机器学习仓库是学术界广泛使用的公开数据集集合，包含大量用于分类、回归、聚类等任务的数据集。论文中使用了其中的20个不平衡数据集，这些数据集具有不同数量的属性、样本和类别不平衡比例，常用于评估过采样和不平衡数据处理方法。
1-s2.0-S0020025520306824-main.pdf,本文提出了一种名为GraphLSHC的大规模超图谱聚类框架，通过引入加权超图来支持复杂的高阶关系，并利用“特征值技巧”（eigen-trick）加速特征问题求解，从而显著降低计算复杂度。此外，该方法创新性地提出基于超边采样的策略，在保留全局图信息的前提下进一步提升性能，为大规模超图谱聚类提供了高效且理论上有误差边界保证的解决方案。,Zoo,一个包含100种动物及其17个属性的数据集，动物被手动分类为7个不同类别。
1-s2.0-S0020025520306824-main.pdf,本文提出了一种名为GraphLSHC的大规模超图谱聚类框架，通过引入加权超图来支持复杂的高阶关系，并利用“特征值技巧”（eigen-trick）加速特征问题求解，从而显著降低计算复杂度。此外，该方法创新性地提出基于超边采样的策略，在保留全局图信息的前提下进一步提升性能，为大规模超图谱聚类提供了高效且理论上有误差边界保证的解决方案。,ORL,一个人脸图像数据集，包含40个不同主体，每个主体生成10张图像，图像尺寸为92×112像素，每个像素具有256级灰度。
1-s2.0-S0020025520306824-main.pdf,本文提出了一种名为GraphLSHC的大规模超图谱聚类框架，通过引入加权超图来支持复杂的高阶关系，并利用“特征值技巧”（eigen-trick）加速特征问题求解，从而显著降低计算复杂度。此外，该方法创新性地提出基于超边采样的策略，在保留全局图信息的前提下进一步提升性能，为大规模超图谱聚类提供了高效且理论上有误差边界保证的解决方案。,USPS,一个由美国邮政服务扫描的手写数字数据集，图像被处理为16×16的灰度图像。
1-s2.0-S0020025520306824-main.pdf,本文提出了一种名为GraphLSHC的大规模超图谱聚类框架，通过引入加权超图来支持复杂的高阶关系，并利用“特征值技巧”（eigen-trick）加速特征问题求解，从而显著降低计算复杂度。此外，该方法创新性地提出基于超边采样的策略，在保留全局图信息的前提下进一步提升性能，为大规模超图谱聚类提供了高效且理论上有误差边界保证的解决方案。,RCV1,一个包含超过80万条新闻报道的语料库，由路透社提供，用于文本分类任务。